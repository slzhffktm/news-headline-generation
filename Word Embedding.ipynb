{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/keyworded.csv').drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_tagged</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_tokens</th>\n",
       "      <th>entities</th>\n",
       "      <th>headline</th>\n",
       "      <th>tokens.1</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('We', 'PRP'), ('neither', 'DT'), ('postracia...</td>\n",
       "      <td>['we', 'neither', 'postracial', 'postgender', ...</td>\n",
       "      <td>['PRP', 'DT', 'JJ', 'NN', 'NNP', 'NNP', 'NNP',...</td>\n",
       "      <td>['we', 'neither', 'postracial', 'postgender', ...</td>\n",
       "      <td>[('PERSON', ['Donna', 'Edwards', 'DMd']), ('OR...</td>\n",
       "      <td>dem rep totally nails why congress is falling ...</td>\n",
       "      <td>['dem', 'rep', 'totally', 'nails', 'why', 'con...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'edward': 0.42, 'essay': 0.256, 'dmd': 0.216,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Vegetables', 'NNS'), ('dont', 'VBP'), ('bor...</td>\n",
       "      <td>['vegetables', 'dont', 'boring', 'relegated', ...</td>\n",
       "      <td>['NNS', 'VBP', 'VBG', 'VBN', 'JJ', 'NN', 'IN',...</td>\n",
       "      <td>['vegetable', 'dont', 'bore', 'relegate', 'sid...</td>\n",
       "      <td>[('PERSON', ['Broccoli', 'Chipotle', 'Honey', ...</td>\n",
       "      <td>eat your veggies  deliciously different recipes</td>\n",
       "      <td>['eat', 'your', 'veggies', 'deliciously', 'dif...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'recipe': 0.365, 'roasted': 0.22, 'cauliflowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[('To', 'TO'), ('extent', 'VB'), ('inheritance...</td>\n",
       "      <td>['to', 'extent', 'inheritance', 'life', 'cumul...</td>\n",
       "      <td>['TO', 'VB', 'NN', 'NNP', 'NN', 'IN', 'NN', 'N...</td>\n",
       "      <td>['to', 'extent', 'inheritance', 'life', 'cumul...</td>\n",
       "      <td>[('ORGANIZATION', ['America', 'Europe', 'Canad...</td>\n",
       "      <td>my white inheritance</td>\n",
       "      <td>['my', 'white', 'inheritance']</td>\n",
       "      <td>0</td>\n",
       "      <td>{'anthony': 0.284, 'family': 0.231, 'inheritan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[('Even', 'RB'), ('years', 'NNS'), ('experienc...</td>\n",
       "      <td>['even', 'years', 'experience', 'process', 're...</td>\n",
       "      <td>['RB', 'NNS', 'RB', 'RB', 'VBG', 'NNS', 'VBG',...</td>\n",
       "      <td>['even', 'year', 'experience', 'process', 'rev...</td>\n",
       "      <td>[('PERSON', ['Leverage']), ('ORGANIZATION', ['...</td>\n",
       "      <td>ways to file your taxes with less stress</td>\n",
       "      <td>['ways', 'to', 'file', 'your', 'taxes', 'with'...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'retirement': 0.492, 'tax': 0.428, 'income': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[('When', 'WRB'), ('Amanda', 'NNP'), ('Peet', ...</td>\n",
       "      <td>['when', 'amanda', 'peet', '’', 'daughter', 'f...</td>\n",
       "      <td>['WRB', 'NNP', 'NNP', 'NNP', 'NN', 'RB', 'VBD'...</td>\n",
       "      <td>['when', 'amanda', 'peet', '’', 'daughter', 'f...</td>\n",
       "      <td>[('PERSON', ['Amanda', 'Peet']), ('PERSON', ['...</td>\n",
       "      <td>amanda peet told her daughter sex is a special...</td>\n",
       "      <td>['amanda', 'peet', 'told', 'her', 'daughter', ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'peet': 0.509, 'frankie': 0.294, 'conan': 0.2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          pos_tagged  \\\n",
       "0  [('We', 'PRP'), ('neither', 'DT'), ('postracia...   \n",
       "1  [('Vegetables', 'NNS'), ('dont', 'VBP'), ('bor...   \n",
       "2  [('To', 'TO'), ('extent', 'VB'), ('inheritance...   \n",
       "3  [('Even', 'RB'), ('years', 'NNS'), ('experienc...   \n",
       "4  [('When', 'WRB'), ('Amanda', 'NNP'), ('Peet', ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['we', 'neither', 'postracial', 'postgender', ...   \n",
       "1  ['vegetables', 'dont', 'boring', 'relegated', ...   \n",
       "2  ['to', 'extent', 'inheritance', 'life', 'cumul...   \n",
       "3  ['even', 'years', 'experience', 'process', 're...   \n",
       "4  ['when', 'amanda', 'peet', '’', 'daughter', 'f...   \n",
       "\n",
       "                                                 pos  \\\n",
       "0  ['PRP', 'DT', 'JJ', 'NN', 'NNP', 'NNP', 'NNP',...   \n",
       "1  ['NNS', 'VBP', 'VBG', 'VBN', 'JJ', 'NN', 'IN',...   \n",
       "2  ['TO', 'VB', 'NN', 'NNP', 'NN', 'IN', 'NN', 'N...   \n",
       "3  ['RB', 'NNS', 'RB', 'RB', 'VBG', 'NNS', 'VBG',...   \n",
       "4  ['WRB', 'NNP', 'NNP', 'NNP', 'NN', 'RB', 'VBD'...   \n",
       "\n",
       "                                        lemma_tokens  \\\n",
       "0  ['we', 'neither', 'postracial', 'postgender', ...   \n",
       "1  ['vegetable', 'dont', 'bore', 'relegate', 'sid...   \n",
       "2  ['to', 'extent', 'inheritance', 'life', 'cumul...   \n",
       "3  ['even', 'year', 'experience', 'process', 'rev...   \n",
       "4  ['when', 'amanda', 'peet', '’', 'daughter', 'f...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  [('PERSON', ['Donna', 'Edwards', 'DMd']), ('OR...   \n",
       "1  [('PERSON', ['Broccoli', 'Chipotle', 'Honey', ...   \n",
       "2  [('ORGANIZATION', ['America', 'Europe', 'Canad...   \n",
       "3  [('PERSON', ['Leverage']), ('ORGANIZATION', ['...   \n",
       "4  [('PERSON', ['Amanda', 'Peet']), ('PERSON', ['...   \n",
       "\n",
       "                                            headline  \\\n",
       "0  dem rep totally nails why congress is falling ...   \n",
       "1    eat your veggies  deliciously different recipes   \n",
       "2                               my white inheritance   \n",
       "3           ways to file your taxes with less stress   \n",
       "4  amanda peet told her daughter sex is a special...   \n",
       "\n",
       "                                            tokens.1  is_sarcastic  \\\n",
       "0  ['dem', 'rep', 'totally', 'nails', 'why', 'con...             0   \n",
       "1  ['eat', 'your', 'veggies', 'deliciously', 'dif...             0   \n",
       "2                     ['my', 'white', 'inheritance']             0   \n",
       "3  ['ways', 'to', 'file', 'your', 'taxes', 'with'...             0   \n",
       "4  ['amanda', 'peet', 'told', 'her', 'daughter', ...             0   \n",
       "\n",
       "                                            keywords  \n",
       "0  {'edward': 0.42, 'essay': 0.256, 'dmd': 0.216,...  \n",
       "1  {'recipe': 0.365, 'roasted': 0.22, 'cauliflowe...  \n",
       "2  {'anthony': 0.284, 'family': 0.231, 'inheritan...  \n",
       "3  {'retirement': 0.492, 'tax': 0.428, 'income': ...  \n",
       "4  {'peet': 0.509, 'frankie': 0.294, 'conan': 0.2...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df[['lemma_tokens']]\n",
    "df_y = df[['tokens.1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_y.index:\n",
    "    df_y.at[i, 'tokens.1'] = ['<startseq>'] + eval(df_y['tokens.1'][i]) + ['<endseq>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Infrequent Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = set()\n",
    "word_sets = [set(eval(l)) for l in df_X['lemma_tokens'].values]\n",
    "for s in word_sets:\n",
    "    word_list = word_list.union(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words before: 87057\n"
     ]
    }
   ],
   "source": [
    "print('number of words before:', len(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dic = {i : 0 for i in word_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_X = []\n",
    "for i in range(len(df_X['lemma_tokens'])):\n",
    "    words_X = eval(df_X['lemma_tokens'].values[i])\n",
    "    sentences_X.append(words_X)\n",
    "    for j in range(len(words_X)):\n",
    "        word_dic[words_X[j]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_threshold = 3\n",
    "\n",
    "new_sentences_X = []\n",
    "for i, sentence_X in enumerate(sentences_X):\n",
    "    new_sentences_X.append([word for word in sentence_X if word_dic[word] >= word_threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words after: 33157\n"
     ]
    }
   ],
   "source": [
    "print('number of words after:', len(set([word for sentence in new_sentences_X for word in sentence])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_X = new_sentences_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245.4086"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(sentence_X) for sentence_X in sentences_X])/len(sentences_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_y = df_y['tokens.1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = set([word for sentence in sentences_y for word in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words after: 16824\n"
     ]
    }
   ],
   "source": [
    "print('number of words before:', len(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dic = {i: 0 for i in word_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence_y in sentences_y:\n",
    "    for word in sentence_y:\n",
    "        word_dic[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_threshold = 3\n",
    "\n",
    "new_sentences_y = []\n",
    "for i, sentence_y in enumerate(sentences_y):\n",
    "    new_sentences_y.append([word for word in sentence_y if word_dic[word] >= word_threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words after: 5409\n"
     ]
    }
   ],
   "source": [
    "print('number of words after:', len(set([word for sentence in new_sentences_y for word in sentence])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_y = new_sentences_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(sentence_y) for sentence_y in sentences_y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemma_tokens'] = sentences_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens.1'] = sentences_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/testing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "w2v = word2vec.Word2Vec\n",
    "body_embedding = w2v(sentences_X, min_count=1, size=100)\n",
    "head_embedding = w2v(sentences_y, min_count=1, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_embedding.save('models/body_embedding.model')\n",
    "head_embedding.save('models/head_embedding.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_body = []\n",
    "vectors_head = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sentences_X)):\n",
    "    vectors_body.append([])\n",
    "    temp = sentences_X[i]\n",
    "    for j in range(len(temp)):\n",
    "        vectors_body[i].append(body_embedding[temp[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_body[0][5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sentences_y)):\n",
    "    vectors_head.append([])\n",
    "    temp = sentences_y[i]\n",
    "    for j in range(len(temp)):\n",
    "        vectors_head[i].append(head_embedding[temp[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_head[0][5].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "body_embedding_fasttext = FastText(sentences_X, size=100, window=5, min_count=1, workers=4,sg=1)\n",
    "head_embedding_fasttext = FastText(sentences_y, size=100, window=5, min_count=1, workers=4,sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_embedding_fasttext.save('models/body_embedding_fasttext.model')\n",
    "head_embedding_fasttext.save('models/head_embedding_fasttext.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
